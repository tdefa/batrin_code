{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0de4e143",
   "metadata": {},
   "source": [
    "## 1) install package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5cb4978",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cellpose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ce71db",
   "metadata": {},
   "source": [
    "## 2) IMPORT PACKAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98caf533",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import nd2\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import tifffile\n",
    "import cellpose\n",
    "from cellpose import models\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import bigfish.detection as detection\n",
    "import bigfish.stack as stack\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d4aea9",
   "metadata": {},
   "source": [
    "## 3 ) Split image channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1b2a0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cdda6c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-feddb6abdf3e>:20: DeprecationWarning: <tifffile.imsave> is deprecated. Use tifffile.imwrite\n",
      "  tifffile.imsave(path_save_ch0 + im_path.name[:-4] + '.tiff', my_array[:,0])\n",
      "<ipython-input-3-feddb6abdf3e>:21: DeprecationWarning: <tifffile.imsave> is deprecated. Use tifffile.imwrite\n",
      "  tifffile.imsave(path_save_ch1 + im_path.name[:-4] + '.tiff', my_array[:,1])\n",
      "<ipython-input-3-feddb6abdf3e>:22: DeprecationWarning: <tifffile.imsave> is deprecated. Use tifffile.imwrite\n",
      "  tifffile.imsave(path_save_ch0_mip + im_path.name[:-4] + '.tiff', np.amax(my_array[:,0], 0))\n",
      "<ipython-input-3-feddb6abdf3e>:23: DeprecationWarning: <tifffile.imsave> is deprecated. Use tifffile.imwrite\n",
      "  tifffile.imsave(path_save_ch1_mip + im_path.name[:-4] + '.tiff', np.amax(my_array[:,1], 0))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### Path to  folder where your images are\n",
    "path_exp_folder  = \"/home/tom/Bureau/phd/Batrin/Images_pour_FISH/Expérience2/\"\n",
    "### Path to folder where you want to save the channel 0\n",
    "path_save_ch0 = \"/home/tom/Bureau/phd/Batrin/Images_pour_FISH/Expérience2/ch0/\"\n",
    "\n",
    "### Path to folder where you want to save the channel 1\n",
    "path_save_ch1 = \"/home/tom/Bureau/phd/Batrin/Images_pour_FISH/Expérience2/ch1/\"\n",
    "### Path to folder where you want to save the channel 0 in 2D\n",
    "path_save_ch0_mip = \"/home/tom/Bureau/phd/Batrin/Images_pour_FISH/Expérience2/ch0_mip/\"\n",
    "\n",
    "### Path to folder where you want to save the channel 1 in 2D\n",
    "path_save_ch1_mip = \"/home/tom/Bureau/phd/Batrin/Images_pour_FISH/Expérience2/ch1_mip/\"\n",
    "\n",
    "Path(path_save_ch0).mkdir(parents=True, exist_ok=True)\n",
    "Path(path_save_ch1).mkdir(parents=True, exist_ok=True)\n",
    "Path(path_save_ch0_mip).mkdir(parents=True, exist_ok=True)\n",
    "Path(path_save_ch1_mip).mkdir(parents=True, exist_ok=True)\n",
    "for im_path in Path(path_exp_folder).glob(f'*.nd2'):\n",
    "    my_array = nd2.imread(im_path)\n",
    "    tifffile.imsave(path_save_ch0 + im_path.name[:-4] + '.tiff', my_array[:,0])\n",
    "    tifffile.imsave(path_save_ch1 + im_path.name[:-4] + '.tiff', my_array[:,1])\n",
    "    tifffile.imsave(path_save_ch0_mip + im_path.name[:-4] + '.tiff', np.amax(my_array[:,0], 0))\n",
    "    tifffile.imsave(path_save_ch1_mip + im_path.name[:-4] + '.tiff', np.amax(my_array[:,1], 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa64833",
   "metadata": {},
   "source": [
    "## 4) cell segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a7645e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##################\n",
    "## Function used for cell segmentation\n",
    "##################\n",
    "\n",
    "\n",
    "def stitch3D_z(masks, stitch_threshold=0.25):\n",
    "    \"\"\" stitch 2D masks into 3D volume with stitch_threshold on IOU \"\"\"\n",
    "    mmax = masks[0].max()\n",
    "    for i in range(len(masks)-1):\n",
    "        try:\n",
    "            iou = cellpose.metrics._intersection_over_union(masks[i+1], masks[i])[1:,1:]\n",
    "            iou[iou < stitch_threshold] = 0.0\n",
    "            iou[iou < iou.max(axis=0)] = 0.0\n",
    "            istitch = iou.argmax(axis=1) + 1\n",
    "            ino = np.nonzero(iou.max(axis=1)==0.0)[0]\n",
    "            istitch[ino] = np.arange(mmax+1, mmax+len(ino)+1, 1, int)\n",
    "            mmax += len(ino)\n",
    "            istitch = np.append(np.array(0), istitch)\n",
    "            masks[i+1] = istitch[masks[i+1]]\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(\"in stich\")\n",
    "            continue\n",
    "    return masks\n",
    "\n",
    "\n",
    "\n",
    "def erase_solitary(mask): #mask en 3D\n",
    "    \"\"\"\n",
    "    Erase nuclei  that are present in only one Z-slice\n",
    "    Args:\n",
    "        mask ():\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "    mask_bis = np.zeros(mask.shape)\n",
    "    current_nuclei = set(np.unique(mask[0]))\n",
    "    post_nuclei = set(np.unique(mask[1]))\n",
    "    nuclei_to_remove =  current_nuclei - post_nuclei\n",
    "    nuclei_to_keep = current_nuclei - nuclei_to_remove # reminder: set operation are different from arithemtic operation\n",
    "    for nuc in nuclei_to_keep:\n",
    "        mask_bis[0] += (mask[0] == nuc) * mask[0]\n",
    "\n",
    "    for i in range(1, len(mask)-1):\n",
    "        pre_nuclei = set(np.unique(mask[i-1]))\n",
    "        current_nuclei = set(np.unique(mask[i]))\n",
    "        post_nuclei = set(np.unique(mask[i+1]))\n",
    "        nuclei_to_remove =  current_nuclei - pre_nuclei - post_nuclei\n",
    "        nuclei_to_keep = current_nuclei - nuclei_to_remove # reminder: set operation are different from arithemtic operation\n",
    "        for nuc in nuclei_to_keep:\n",
    "            mask_bis[i] += (mask[i] == nuc) *  mask[i]\n",
    "    ##traiter le cas ou n = -1\n",
    "    current_nuclei = set(np.unique(mask[-1]))\n",
    "    pre_nuclei = set(np.unique(mask[-2]))\n",
    "    nuclei_to_remove =  current_nuclei - pre_nuclei\n",
    "    nuclei_to_keep = current_nuclei - nuclei_to_remove # reminder: set operation are different from arithemtic operation\n",
    "    for nuc in nuclei_to_keep:\n",
    "        mask_bis[-1] += (mask[-1] == nuc) * mask[-1]\n",
    "    return mask_bis\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def erase_small_nuclei(mask, min_size = 340):\n",
    "    for nuc in tqdm(np.unique(mask)[1:]): ## remove zero\n",
    "        sum_size = np.sum((mask == nuc).astype(int))\n",
    "        print(sum_size)\n",
    "        if sum_size < min_size:\n",
    "                mask[mask == nuc] = 0\n",
    "    return mask\n",
    "\n",
    "\n",
    "def segment_nuclei(path_to_dapi_folder,\n",
    "                   regex_dapi,\n",
    "                   path_to_mask_dapi,\n",
    "                   dico_param,\n",
    "                   model,\n",
    "                   save=True,\n",
    "                   ):\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    segment dapi image and save  them in th path_to_mask_dapi folder\n",
    "    Args:\n",
    "        path_to_dapi (str):\n",
    "        path_to_mask_dapi (str):\n",
    "        dico_param (dict):\n",
    "        model (cellpose modem):\n",
    "        save (bool):\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    if path_to_mask_dapi[-1] != \"/\":\n",
    "        path_to_mask_dapi += \"/\"\n",
    "    print(list(Path(path_to_dapi_folder).glob(f\"*{regex_dapi}*\")))\n",
    "    print(f'dico_param{dico_param}')\n",
    "    for path_dapi in tqdm(list(Path(path_to_dapi_folder).glob(f\"*{regex_dapi}*\"))):\n",
    "        path_dapi = str(path_dapi)\n",
    "        print(path_dapi)\n",
    "        img = tifffile.imread(path_dapi)\n",
    "        print(img.shape)\n",
    "        if dico_param[\"mip\"] is True and len(img.shape) == 3:\n",
    "            img = np.amax(img, 0)\n",
    "        else:\n",
    "            if len(img.shape) == 3:\n",
    "                img = img.reshape(img.shape[0], 1, img.shape[1], img.shape[2])\n",
    "                print(f'image dapi shape after reshape {img.shape}')\n",
    "                img = list(img)\n",
    "        masks, flows, styles, diams = model.eval(img, diameter=dico_param[\"diameter\"],\n",
    "                                                 channels=[0, 0],\n",
    "                                                 flow_threshold=dico_param[\"flow_threshold\"],\n",
    "                                                 do_3D=dico_param[\"do_3D\"],\n",
    "                                                 stitch_threshold=0)\n",
    "\n",
    "        if len(masks.shape) == 3:\n",
    "            masks = stitch3D_z(masks, dico_param[\"stitch_threshold\"])\n",
    "            masks = np.array(masks, dtype = np.int16)\n",
    "            if len(masks.shape) and dico_param[\"erase_solitary\"]:\n",
    "                masks = erase_solitary(masks)\n",
    "        if dico_param[\"erase_small_nuclei\"] is not None:\n",
    "            print(f'erase_small_nuclei threshold {dico_param[\"erase_small_nuclei\"]}')\n",
    "            masks = erase_small_nuclei(masks)\n",
    "        if save:\n",
    "            image_name = path_dapi.split('/')[-1].split(f'_{regex_dapi}')[0]\n",
    "            tifffile.imwrite(path_to_mask_dapi + image_name +'.tif', data=masks, dtype=masks.dtype)\n",
    "            np.save(path_to_mask_dapi + \"dico_param.npy\", dico_param)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d04491e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "[PosixPath('/home/tom/Bureau/phd/Batrin/Images_pour_FISH/Expérience2/ch1_mip/WT_pCenTy_002.tiff'), PosixPath('/home/tom/Bureau/phd/Batrin/Images_pour_FISH/Expérience2/ch1_mip/Delta_adk1_pCenTy_001.tiff'), PosixPath('/home/tom/Bureau/phd/Batrin/Images_pour_FISH/Expérience2/ch1_mip/Delta_adk1_pCenTy_003.tiff'), PosixPath('/home/tom/Bureau/phd/Batrin/Images_pour_FISH/Expérience2/ch1_mip/WT_pCenTy_001.tiff'), PosixPath('/home/tom/Bureau/phd/Batrin/Images_pour_FISH/Expérience2/ch1_mip/Delta_adk1_pCenTy_002.tiff')]\n",
      "dico_param{'diameter': 20, 'flow_threshold': 0.8, 'mask_threshold': 0, 'do_3D': False, 'mip': False, 'projected_focused': False, 'stitch_threshold': 0.3, 'erase_solitary': False, 'erase_small_nuclei': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tom/Bureau/phd/Batrin/Images_pour_FISH/Expérience2/ch1_mip/WT_pCenTy_002.tiff\n",
      "(2160, 2560)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 1/5 [00:51<03:25, 51.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tom/Bureau/phd/Batrin/Images_pour_FISH/Expérience2/ch1_mip/Delta_adk1_pCenTy_001.tiff\n",
      "(2160, 2560)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 2/5 [01:54<02:54, 58.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tom/Bureau/phd/Batrin/Images_pour_FISH/Expérience2/ch1_mip/Delta_adk1_pCenTy_003.tiff\n",
      "(2160, 2560)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 3/5 [03:00<02:03, 61.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tom/Bureau/phd/Batrin/Images_pour_FISH/Expérience2/ch1_mip/WT_pCenTy_001.tiff\n",
      "(2160, 2560)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 4/5 [04:10<01:04, 64.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tom/Bureau/phd/Batrin/Images_pour_FISH/Expérience2/ch1_mip/Delta_adk1_pCenTy_002.tiff\n",
      "(2160, 2560)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [05:18<00:00, 63.79s/it]\n"
     ]
    }
   ],
   "source": [
    "#### run segmentation\n",
    "\n",
    "### folder with your dapi images (2D or 3D)\n",
    "path_to_dapi_folder = path_exp_folder + \"ch1_mip/\"\n",
    "\n",
    "## Folder where you save segmentation mask \n",
    "path_to_mask_dapi = path_exp_folder + \"ch1_mask_mip/\"\n",
    "\n",
    "\n",
    "Path(path_to_mask_dapi).mkdir(parents=True, exist_ok=True)\n",
    "model_name = \"cyto\"\n",
    "model = models.Cellpose(model_type=model_name)\n",
    "dico_param = {}\n",
    "dico_param[\"diameter\"] = 80\n",
    "dico_param[\"flow_threshold\"] = 0.8\n",
    "dico_param[\"mask_threshold\"] = 0\n",
    "dico_param[\"do_3D\"] = False\n",
    "dico_param[\"mip\"] = False\n",
    "dico_param[\"projected_focused\"] = False\n",
    "dico_param[\"stitch_threshold\"] = 0.3\n",
    "dico_param[\"erase_solitary\"] = False\n",
    "dico_param[\"erase_small_nuclei\"] = None\n",
    "\n",
    "for i in range(20, 19, -10):\n",
    "    print(i)\n",
    "    dico_param[\"diameter\"] = i\n",
    "\n",
    "    path_to_mask_dapi_loop = path_to_mask_dapi + str(i) + \"_\"+ model_name + \"/\"\n",
    "    Path(path_to_mask_dapi_loop).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    segment_nuclei(path_to_dapi_folder=path_to_dapi_folder,\n",
    "                   regex_dapi=\"ti\",\n",
    "                   path_to_mask_dapi=path_to_mask_dapi_loop,\n",
    "                   dico_param=dico_param,\n",
    "                   model=model,\n",
    "                   save=True,\n",
    "                   )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ada9f93",
   "metadata": {},
   "source": [
    "## 5) SPOT DETECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e01bd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detection_without_segmentation(\n",
    "                            rna,\n",
    "                            sigma,\n",
    "                            min_distance = [3,3, 3],\n",
    "                            threshold = None):\n",
    "\n",
    "\n",
    "    rna_log = stack.log_filter(rna, sigma)\n",
    "    mask = detection.local_maximum_detection(rna_log, min_distance=min_distance)\n",
    "\n",
    "    if threshold is None:\n",
    "        threshold = detection.automated_threshold_setting(rna_log, mask)\n",
    "    spots, _ = detection.spots_thresholding(rna_log, mask, threshold)\n",
    "    return spots\n",
    "\n",
    "def detection_folder(\n",
    "                     round_folder_path = \"/media/tom/T7/Stitch/acquisition/\",\n",
    "                     round_name_regex = \"r\",\n",
    "                     image_name_regex = \"opool1_1_MMStack_3\",\n",
    "                     channel_name_regex = \"ch1\",\n",
    "                     fixed_round_name = \"r1_bc1\",\n",
    "                     path_output_segmentaton = \"/media/tom/T7/stich0504/segmentation_mask/\",\n",
    "                      min_distance=(4, 4, 4),\n",
    "                      scale_xy=0.103,\n",
    "                      scale_z=0.300,\n",
    "                      sigma = 1.35,\n",
    "                        ### detection parameters with segmentation\n",
    "                    dico_translation = np.load(\"/media/tom/T7/Stitch/acquisition/dico_translation.npy\", allow_pickle=True).item(),\n",
    "                    diam_um=20,\n",
    "                    local_detection = True,\n",
    "                    min_cos_tetha=0.75,\n",
    "                    order=5,\n",
    "                    test_mode=False,\n",
    "                    threshold_merge_limit= 0.330):\n",
    "    \"\"\"\n",
    "\n",
    "    :param sigma:\n",
    "    :param rna_path:\n",
    "    :param path_output_segmentaton:\n",
    "    :param threshold_input:\n",
    "    :param output_file:\n",
    "    :param min_distance:\n",
    "    :param local_detection:\n",
    "    :param diam:\n",
    "    :param scale_xy:\n",
    "    :param scale_z:\n",
    "    :param min_cos_tetha:\n",
    "    :param order:\n",
    "    :param test_mode:\n",
    "    :return:\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    dico_spots = {}\n",
    "    dico_intensity = {}\n",
    "    for path_round in tqdm(list(Path(round_folder_path).glob(f\"{round_name_regex}*\"))[4:] + list(Path(round_folder_path).glob(f\"{round_name_regex}*\"))):\n",
    "        print()\n",
    "        print(path_round.name)\n",
    "        dico_spots[path_round.name] = {}\n",
    "        for path_rna_img in tqdm(list(path_round.glob(f\"*{channel_name_regex}*ti*\"))):\n",
    "\n",
    "            if image_name_regex not in path_rna_img.name:\n",
    "                continue\n",
    "            print(path_rna_img.name)\n",
    "\n",
    "            rna_img = tifffile.imread(path_rna_img)\n",
    "\n",
    "            \n",
    "            all_spots = detection_without_segmentation(\n",
    "                            rna=rna_img,\n",
    "                            sigma=sigma,\n",
    "                            min_distance=min_distance,\n",
    "                            threshold = None\n",
    "                )\n",
    "            dico_spots[path_round.name][path_rna_img.name] = all_spots\n",
    "            \n",
    "    return dico_spots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e34c4edc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ch0_mip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WT_pCenTy_002.tiff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 1/5 [00:00<00:03,  1.05it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delta_adk1_pCenTy_001.tiff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|████      | 2/5 [00:01<00:02,  1.30it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delta_adk1_pCenTy_003.tiff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 3/5 [00:02<00:01,  1.33it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WT_pCenTy_001.tiff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████  | 4/5 [00:03<00:00,  1.29it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delta_adk1_pCenTy_002.tiff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:03<00:00,  1.32it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.79s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "round_folder_path  = \"/home/tom/Bureau/phd/Batrin/Images_pour_FISH/Expérience2/round_folder/\"\n",
    "\n",
    "dico_spots = detection_folder(\n",
    "    round_folder_path=round_folder_path,\n",
    "    round_name_regex=\"ch\",\n",
    "    image_name_regex=\"ti\",\n",
    "    channel_name_regex=\".\",\n",
    "    min_distance=(3, 3),\n",
    "    sigma=1,\n",
    "    fixed_round_name=None,\n",
    "    path_output_segmentaton=None,\n",
    "    scale_xy=None,\n",
    "    scale_z=None,\n",
    "    ### detection parameters with segmentation\n",
    "    dico_translation=None,\n",
    "    diam_um=None,\n",
    "    local_detection=None,\n",
    "    min_cos_tetha=None,\n",
    "    order=None,\n",
    "    test_mode=None,\n",
    "    threshold_merge_limit=None)\n",
    "\n",
    "\n",
    "#### dico spot to csv\n",
    "\n",
    "np.save(round_folder_path+\"dico_spots.npy\", dico_spots)\n",
    "Path(round_folder_path+\"detection_csv/\").mkdir(parents=True, exist_ok=True)\n",
    "for round_name in dico_spots.keys():\n",
    "    for image_name in dico_spots[round_name].keys():\n",
    "        df = pd.DataFrame(dico_spots[round_name][image_name])\n",
    "        df = df.rename(columns={0: \"x\", 1: \"y\"})\n",
    "        df.to_csv(f\"{round_folder_path}detection_csv/{image_name}.csv\",\n",
    "                  index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff6faaa",
   "metadata": {},
   "source": [
    "# Count spots per nucleus and intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36786292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delta_adk1_pCenTy_003.tiff.tif\n",
      "WT_pCenTy_002.tiff.tif\n",
      "WT_pCenTy_001.tiff.tif\n",
      "Delta_adk1_pCenTy_002.tiff.tif\n",
      "Delta_adk1_pCenTy_001.tiff.tif\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "path_main_folder  = \"/home/tom/Bureau/phd/Batrin/Images_pour_FISH/Expérience2/\"\n",
    "path_ch0 = path_main_folder + \"round_folder/ch0_mip/\"\n",
    "path_mask_folder  = path_main_folder + \"ch1_mask_mip/20_cyto/\"\n",
    "path_csv_folder = path_main_folder + \"round_folder/detection_csv/\"\n",
    "dico_mean_spots = {}\n",
    "\n",
    "dico_snr = {}\n",
    "dico_mean_intensity = {}\n",
    "dico_mean_intensity_normalize = {}\n",
    "\n",
    "\n",
    "for path_mask in Path(path_mask_folder).glob(\"*tif*\"):\n",
    "    print(path_mask.name)\n",
    "    mask = tifffile.imread(path_mask)\n",
    "    img_fish = tifffile.imread(path_ch0 + path_mask.name[:-4])\n",
    "    img_fish_mean = stack.mean_filter(img_fish, kernel_shape = \"square\", kernel_size = 4)\n",
    "\n",
    "\n",
    "    df_spots = pd.read_csv(path_csv_folder + path_mask.name[:-4] + \".csv\")\n",
    "    df_spots['in_mask'] = 0\n",
    "    df_spots['mean_intensity'] = 0\n",
    "    df_spots['normalized_mean_intensity'] = 0\n",
    "\n",
    "    list_spots = np.array([[x,y] for x, y in zip(df_spots['x'], df_spots['y'])])\n",
    "    snr  = detection.compute_snr_spots(img_fish, list_spots, voxel_size = 108, spot_radius= 300)\n",
    "    dico_snr[path_mask.name[:-4]] = snr\n",
    "    list_mean_intensity = []\n",
    "    mean_norm = np.mean(img_fish_mean[mask == 0])\n",
    "    for i in range(len(df_spots)):\n",
    "        if mask[int(df_spots['x'][i]), int(df_spots['y'][i])]  !=0:\n",
    "            df_spots['in_mask'][i] =  mask[int(df_spots['x'][i]), int(df_spots['y'][i])]\n",
    "            list_mean_intensity.append(img_fish_mean[int(df_spots['x'][i]), int(df_spots['y'][i])])\n",
    "\n",
    "\n",
    "        df_spots['mean_intensity'][i] = img_fish_mean[int(df_spots['x'][i]), int(df_spots['y'][i])]\n",
    "        df_spots['normalized_mean_intensity'][i] = img_fish_mean[int(df_spots['x'][i]), int(df_spots['y'][i])] / mean_norm\n",
    "    df_spots.to_csv(path_csv_folder + path_mask.name[:-4] + \".csv\", index=False)\n",
    "\n",
    "    dico_mean_spots[path_mask.name[:-4]] = np.sum(df_spots['in_mask'] != 0) / len(np.unique(mask)[1:])\n",
    "\n",
    "    dico_mean_intensity[path_mask.name[:-4]] = np.mean(list_mean_intensity)\n",
    "\n",
    "    dico_mean_intensity_normalize[path_mask.name[:-4]] = np.mean(list_mean_intensity) / np.mean(img_fish_mean[mask == 0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff707cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "batrin",
   "language": "python",
   "name": "batrin"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
