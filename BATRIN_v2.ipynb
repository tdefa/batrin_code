{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0de4e143",
   "metadata": {},
   "source": [
    "## 1) install package"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afca917",
   "metadata": {},
   "source": [
    "## use the provided conda env \n",
    "\n",
    "### run in a (linux) console the following command:\n",
    "\n",
    "### conda create --name batrin --file batrin_pkgs.txt\n",
    "### conda activate batrin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ce71db",
   "metadata": {},
   "source": [
    "## 2) IMPORT PACKAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98caf533",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import nd2\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import tifffile\n",
    "import cellpose\n",
    "from cellpose import models\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import bigfish.detection as detection\n",
    "import bigfish.stack as stack\n",
    "import pandas as pd\n",
    "from pathlib import Path "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d4aea9",
   "metadata": {},
   "source": [
    "## 3 ) Split image channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a1b2a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PARAMTERS\n",
    "\n",
    "\n",
    "### Path to folder where your images are\n",
    "path_exp_folder  = \"/home/tom/Bureau/phd/Batrin/test/\"\n",
    "\n",
    "### Path to folder where you want to save the channel 0\n",
    "path_save_ch0 = \"/home/tom/Bureau/phd/Batrin/test/ch0_3D/\"\n",
    "\n",
    "### Path to folder where you want to save the channel 1\n",
    "path_save_ch1 = \"/home/tom/Bureau/phd/Batrin/test/ch1_3D/\"\n",
    "\n",
    "### Path to folder where you want to save the channel 0 in 2D\n",
    "path_save_ch0_mip = \"/home/tom/Bureau/phd/Batrin/test/ch0_mip/\"\n",
    "\n",
    "### Path to folder where you want to save the channel 1 in 2D\n",
    "path_save_ch1_mip = \"/home/tom/Bureau/phd/Batrin/test/ch1_mip/\"\n",
    "\n",
    "Path(path_save_ch0).mkdir(parents=True, exist_ok=True)\n",
    "Path(path_save_ch1).mkdir(parents=True, exist_ok=True)\n",
    "Path(path_save_ch0_mip).mkdir(parents=True, exist_ok=True)\n",
    "Path(path_save_ch1_mip).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0cdda6c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-21-6c2d7cc8534c>:7: DeprecationWarning: <tifffile.imsave> is deprecated. Use tifffile.imwrite\n",
      "  tifffile.imsave(path_save_ch0 + im_path.name[:-4] + '.tiff', my_array[:,0])\n",
      "<ipython-input-21-6c2d7cc8534c>:8: DeprecationWarning: <tifffile.imsave> is deprecated. Use tifffile.imwrite\n",
      "  tifffile.imsave(path_save_ch1 + im_path.name[:-4] + '.tiff', my_array[:,1])\n",
      "<ipython-input-21-6c2d7cc8534c>:9: DeprecationWarning: <tifffile.imsave> is deprecated. Use tifffile.imwrite\n",
      "  tifffile.imsave(path_save_ch0_mip + im_path.name[:-4] + '.tiff', np.amax(my_array[:,0], 0))\n",
      "<ipython-input-21-6c2d7cc8534c>:10: DeprecationWarning: <tifffile.imsave> is deprecated. Use tifffile.imwrite\n",
      "  tifffile.imsave(path_save_ch1_mip + im_path.name[:-4] + '.tiff', np.amax(my_array[:,1], 0))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "Path(path_save_ch0).mkdir(parents=True, exist_ok=True)\n",
    "Path(path_save_ch1).mkdir(parents=True, exist_ok=True)\n",
    "Path(path_save_ch0_mip).mkdir(parents=True, exist_ok=True)\n",
    "Path(path_save_ch1_mip).mkdir(parents=True, exist_ok=True)\n",
    "for im_path in Path(path_exp_folder).glob(f'*.nd2'):\n",
    "    my_array = nd2.imread(im_path)\n",
    "    tifffile.imsave(path_save_ch0 + im_path.name[:-4] + '.tiff', my_array[:,0])\n",
    "    tifffile.imsave(path_save_ch1 + im_path.name[:-4] + '.tiff', my_array[:,1])\n",
    "    tifffile.imsave(path_save_ch0_mip + im_path.name[:-4] + '.tiff', np.amax(my_array[:,0], 0))\n",
    "    tifffile.imsave(path_save_ch1_mip + im_path.name[:-4] + '.tiff', np.amax(my_array[:,1], 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa64833",
   "metadata": {},
   "source": [
    "## 4) cell segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a7645e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##################\n",
    "## Function used for cell segmentation\n",
    "##################\n",
    "\n",
    "\n",
    "def stitch3D_z(masks, stitch_threshold=0.25):\n",
    "    \"\"\" stitch 2D masks into 3D volume with stitch_threshold on IOU \"\"\"\n",
    "    mmax = masks[0].max()\n",
    "    for i in range(len(masks)-1):\n",
    "        try:\n",
    "            iou = cellpose.metrics._intersection_over_union(masks[i+1], masks[i])[1:,1:]\n",
    "            iou[iou < stitch_threshold] = 0.0\n",
    "            iou[iou < iou.max(axis=0)] = 0.0\n",
    "            istitch = iou.argmax(axis=1) + 1\n",
    "            ino = np.nonzero(iou.max(axis=1)==0.0)[0]\n",
    "            istitch[ino] = np.arange(mmax+1, mmax+len(ino)+1, 1, int)\n",
    "            mmax += len(ino)\n",
    "            istitch = np.append(np.array(0), istitch)\n",
    "            masks[i+1] = istitch[masks[i+1]]\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(\"in stich\")\n",
    "            continue\n",
    "    return masks\n",
    "\n",
    "\n",
    "\n",
    "def erase_solitary(mask): #mask en 3D\n",
    "    \"\"\"\n",
    "    Erase nuclei  that are present in only one Z-slice\n",
    "    Args:\n",
    "        mask ():\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "    mask_bis = np.zeros(mask.shape)\n",
    "    current_nuclei = set(np.unique(mask[0]))\n",
    "    post_nuclei = set(np.unique(mask[1]))\n",
    "    nuclei_to_remove =  current_nuclei - post_nuclei\n",
    "    nuclei_to_keep = current_nuclei - nuclei_to_remove # reminder: set operation are different from arithemtic operation\n",
    "    for nuc in nuclei_to_keep:\n",
    "        mask_bis[0] += (mask[0] == nuc) * mask[0]\n",
    "\n",
    "    for i in range(1, len(mask)-1):\n",
    "        pre_nuclei = set(np.unique(mask[i-1]))\n",
    "        current_nuclei = set(np.unique(mask[i]))\n",
    "        post_nuclei = set(np.unique(mask[i+1]))\n",
    "        nuclei_to_remove =  current_nuclei - pre_nuclei - post_nuclei\n",
    "        nuclei_to_keep = current_nuclei - nuclei_to_remove # reminder: set operation are different from arithemtic operation\n",
    "        for nuc in nuclei_to_keep:\n",
    "            mask_bis[i] += (mask[i] == nuc) *  mask[i]\n",
    "    ##traiter le cas ou n = -1\n",
    "    current_nuclei = set(np.unique(mask[-1]))\n",
    "    pre_nuclei = set(np.unique(mask[-2]))\n",
    "    nuclei_to_remove =  current_nuclei - pre_nuclei\n",
    "    nuclei_to_keep = current_nuclei - nuclei_to_remove # reminder: set operation are different from arithemtic operation\n",
    "    for nuc in nuclei_to_keep:\n",
    "        mask_bis[-1] += (mask[-1] == nuc) * mask[-1]\n",
    "    return mask_bis\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def erase_small_nuclei(mask, min_size = 340):\n",
    "    for nuc in tqdm(np.unique(mask)[1:]): ## remove zero\n",
    "        sum_size = np.sum((mask == nuc).astype(int))\n",
    "        print(sum_size)\n",
    "        if sum_size < min_size:\n",
    "                mask[mask == nuc] = 0\n",
    "    return mask\n",
    "\n",
    "\n",
    "def segment_nuclei(path_to_dapi_folder,\n",
    "                   regex_dapi,\n",
    "                   path_to_mask_dapi,\n",
    "                   dico_param,\n",
    "                   model,\n",
    "                   save=True,\n",
    "                   ):\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    segment dapi image and save  them in th path_to_mask_dapi folder\n",
    "    Args:\n",
    "        path_to_dapi (str):\n",
    "        path_to_mask_dapi (str):\n",
    "        dico_param (dict):\n",
    "        model (cellpose modem):\n",
    "        save (bool):\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    if path_to_mask_dapi[-1] != \"/\":\n",
    "        path_to_mask_dapi += \"/\"\n",
    "    print(list(Path(path_to_dapi_folder).glob(f\"*{regex_dapi}*\")))\n",
    "    print(f'dico_param{dico_param}')\n",
    "    for path_dapi in tqdm(list(Path(path_to_dapi_folder).glob(f\"*{regex_dapi}*\"))):\n",
    "        path_dapi = str(path_dapi)\n",
    "        print(path_dapi)\n",
    "        img = tifffile.imread(path_dapi)\n",
    "        print(img.shape)\n",
    "        if dico_param[\"mip\"] is True and len(img.shape) == 3:\n",
    "            img = np.amax(img, 0)\n",
    "        else:\n",
    "            if len(img.shape) == 3:\n",
    "                img = img.reshape(img.shape[0], 1, img.shape[1], img.shape[2])\n",
    "                print(f'image dapi shape after reshape {img.shape}')\n",
    "                img = list(img)\n",
    "        masks, flows, styles, diams = model.eval(img, diameter=dico_param[\"diameter\"],\n",
    "                                                 channels=[0, 0],\n",
    "                                                 flow_threshold=dico_param[\"flow_threshold\"],\n",
    "                                                 do_3D=dico_param[\"do_3D\"],\n",
    "                                                 stitch_threshold=0)\n",
    "\n",
    "        if len(masks.shape) == 3:\n",
    "            masks = stitch3D_z(masks, dico_param[\"stitch_threshold\"])\n",
    "            masks = np.array(masks, dtype = np.int16)\n",
    "            if len(masks.shape) and dico_param[\"erase_solitary\"]:\n",
    "                masks = erase_solitary(masks)\n",
    "        if dico_param[\"erase_small_nuclei\"] is not None:\n",
    "            print(f'erase_small_nuclei threshold {dico_param[\"erase_small_nuclei\"]}')\n",
    "            masks = erase_small_nuclei(masks)\n",
    "        if save:\n",
    "            image_name = path_dapi.split('/')[-1].split(f'_{regex_dapi}')[0]\n",
    "            tifffile.imwrite(path_to_mask_dapi + image_name +'.tif', data=masks, dtype=masks.dtype)\n",
    "            np.save(path_to_mask_dapi + \"dico_param.npy\", dico_param)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d6eecd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PARAMETERS\n",
    "\n",
    "### folder with your dapi images (2D or 3D)\n",
    "path_to_dapi_folder = path_exp_folder + \"ch1_mip/\"\n",
    "\n",
    "## Folder where you will save segmentation mask \n",
    "path_to_mask_dapi = path_exp_folder + \"ch1_mask_mip/\"\n",
    "Path(path_to_mask_dapi).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d04491e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'path_to_mask_dapi' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-5b78e9d2cc4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_mask_dapi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cyto\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCellpose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'path_to_mask_dapi' is not defined"
     ]
    }
   ],
   "source": [
    "#### run segmentation\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Path(path_to_mask_dapi).mkdir(parents=True, exist_ok=True)\n",
    "model_name = \"cyto\"\n",
    "model = models.Cellpose(model_type=model_name)\n",
    "dico_param = {}\n",
    "dico_param[\"diameter\"] = 80\n",
    "dico_param[\"flow_threshold\"] = 0.8\n",
    "dico_param[\"mask_threshold\"] = 0\n",
    "dico_param[\"do_3D\"] = False\n",
    "dico_param[\"mip\"] = False\n",
    "dico_param[\"projected_focused\"] = False\n",
    "dico_param[\"stitch_threshold\"] = 0.3\n",
    "dico_param[\"erase_solitary\"] = False\n",
    "dico_param[\"erase_small_nuclei\"] = None\n",
    "\n",
    "for i in range(20, 19, -10):\n",
    "    print(i)\n",
    "    dico_param[\"diameter\"] = i\n",
    "\n",
    "    path_to_mask_dapi_loop = path_to_mask_dapi + str(i) + \"_\"+ model_name + \"/\"\n",
    "    Path(path_to_mask_dapi_loop).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    segment_nuclei(path_to_dapi_folder=path_to_dapi_folder,\n",
    "                   regex_dapi=\"ti\",\n",
    "                   path_to_mask_dapi=path_to_mask_dapi_loop,\n",
    "                   dico_param=dico_param,\n",
    "                   model=model,\n",
    "                   save=True,\n",
    "                   )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ada9f93",
   "metadata": {},
   "source": [
    "## 5) SPOT DETECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e01bd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detection_without_segmentation(\n",
    "                            rna,\n",
    "                            sigma,\n",
    "                            min_distance = [3,3, 3],\n",
    "                            threshold = None):\n",
    "\n",
    "\n",
    "    rna_log = stack.log_filter(rna, sigma)\n",
    "    mask = detection.local_maximum_detection(rna_log, min_distance=min_distance)\n",
    "\n",
    "    if threshold is None:\n",
    "        threshold = detection.automated_threshold_setting(rna_log, mask)\n",
    "    spots, _ = detection.spots_thresholding(rna_log, mask, threshold)\n",
    "    return spots\n",
    "\n",
    "def detection_folder(\n",
    "                     round_folder_path = \"/media/tom/T7/Stitch/acquisition/\",\n",
    "                     round_name_regex = \"r\",\n",
    "                     image_name_regex = \"opool1_1_MMStack_3\",\n",
    "                     channel_name_regex = \"ch1\",\n",
    "                     fixed_round_name = \"r1_bc1\",\n",
    "                     path_output_segmentaton = \"/media/tom/T7/stich0504/segmentation_mask/\",\n",
    "                      min_distance=(4, 4, 4),\n",
    "                      scale_xy=0.103,\n",
    "                      scale_z=0.300,\n",
    "                      sigma = 1.35,\n",
    "                    ):\n",
    "    \"\"\"\n",
    "\n",
    "    :param sigma:\n",
    "    :param rna_path:\n",
    "    :param path_output_segmentaton:\n",
    "    :param threshold_input:\n",
    "    :param output_file:\n",
    "    :param min_distance:\n",
    "    :param local_detection:\n",
    "    :param diam:\n",
    "    :param scale_xy:\n",
    "    :param scale_z:\n",
    "    :param min_cos_tetha:\n",
    "    :param order:\n",
    "    :param test_mode:\n",
    "    :return:\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    dico_spots = {}\n",
    "    dico_intensity = {}\n",
    "    for path_round in tqdm(list(Path(round_folder_path).glob(f\"{round_name_regex}*\"))[4:] + list(Path(round_folder_path).glob(f\"{round_name_regex}*\"))):\n",
    "        print()\n",
    "        print(path_round.name)\n",
    "        dico_spots[path_round.name] = {}\n",
    "        for path_rna_img in tqdm(list(path_round.glob(f\"*{channel_name_regex}*ti*\"))):\n",
    "\n",
    "            if image_name_regex not in path_rna_img.name:\n",
    "                continue\n",
    "            print(path_rna_img.name)\n",
    "\n",
    "            rna_img = tifffile.imread(path_rna_img)\n",
    "\n",
    "            \n",
    "            all_spots = detection_without_segmentation(\n",
    "                            rna=rna_img,\n",
    "                            sigma=sigma,\n",
    "                            min_distance=min_distance,\n",
    "                            threshold = None\n",
    "                )\n",
    "            dico_spots[path_round.name][path_rna_img.name] = all_spots\n",
    "            \n",
    "    return dico_spots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf98c53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tom/Bureau/phd/Batrin/test/result/\n"
     ]
    }
   ],
   "source": [
    "## PARAMETER\n",
    "\n",
    "## PATH THE FOLDER WHERE TO SAVE THE CSV spot position and the spots position dictionnary\n",
    "path_result  = path_exp_folder  +\"result/\"\n",
    "Path(path_result).mkdir(parents=True, exist_ok=True)\n",
    "print(path_result)\n",
    "\n",
    "\n",
    "### chose between 3D and 2D \n",
    "\n",
    "## 2D\n",
    "round_name_regex=\"ch0_mip\"\n",
    "min_distance=(3, 3)\n",
    "\n",
    "# 3D\n",
    "#round_name_regex=\"ch0_mip\"\n",
    "#min_distance=(3, 3, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e34c4edc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ch0_mip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delta_adk1_pCenTy_001.tiff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.60it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.59it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "dico_spots = detection_folder(\n",
    "    round_folder_path=path_exp_folder,\n",
    "    round_name_regex=round_name_regex,\n",
    "    image_name_regex=\"ti\",\n",
    "    channel_name_regex=\".\",\n",
    "    min_distance=min_distance,\n",
    "    sigma=1,\n",
    "    fixed_round_name=None,\n",
    "    path_output_segmentaton=None,\n",
    "    scale_xy=None,\n",
    "    scale_z=None,\n",
    "    )\n",
    "\n",
    "\n",
    "#### dico spot to csv\n",
    "\n",
    "np.save(path_result+\"dico_spots.npy\", dico_spots)\n",
    "Path(path_result+\"detection_csv/\").mkdir(parents=True, exist_ok=True)\n",
    "for round_name in dico_spots.keys():\n",
    "    for image_name in dico_spots[round_name].keys():\n",
    "        df = pd.DataFrame(dico_spots[round_name][image_name])\n",
    "        if len(min_distance)==2: ## 2D \n",
    "            df = df.rename(columns={0: \"x\", 1: \"y\"})\n",
    "        else:\n",
    "            assert len(min_distance) == 3 ##3D \n",
    "            df = df.rename(columns={0: \"x\", 1: \"y\", 2: \"z\"})\n",
    "        df.to_csv(f\"{path_result}detection_csv/{image_name}.csv\",\n",
    "                  index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8bb95e",
   "metadata": {},
   "source": [
    "# Count spots per nucleus and intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1750c974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/tom/Bureau/phd/Batrin/test/result/detection_csv/'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PARAMETER\n",
    "\n",
    "\n",
    "### Path to folder where your images are\n",
    "\n",
    "\n",
    "### Path to folder where you saveD the channel 0 (FISH) in 2D or 3D \n",
    "path_ch0 = path_exp_folder + \"ch0_mip/\"\n",
    "\n",
    "\n",
    "### Path to folder where you save the nuclei mask\n",
    "path_mask_folder  = path_exp_folder + \"ch1_mask_mip/20_cyto/\"\n",
    "\n",
    "\n",
    "## Path to csv \n",
    "path_csv_folder = path_result + \"detection_csv/\"\n",
    "path_csv_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36786292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delta_adk1_pCenTy_001.tiff.tif\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### if you want to use it for 3D you have to replace \n",
    "#\"df_spots['x'], df_spots['y']\" per df_spots['x'], df_spots['y'], df_spots['z'] \n",
    "\n",
    "\n",
    "dico_mean_spots = {}\n",
    "\n",
    "dico_snr = {}\n",
    "dico_mean_intensity = {}\n",
    "dico_mean_intensity_normalize = {}\n",
    "\n",
    "\n",
    "for path_mask in Path(path_mask_folder).glob(\"*tif*\"):\n",
    "    print(path_mask.name)\n",
    "    mask = tifffile.imread(path_mask)\n",
    "    img_fish = tifffile.imread(path_ch0 + path_mask.name[:-4])\n",
    "    img_fish_mean = stack.mean_filter(img_fish, kernel_shape = \"square\", kernel_size = 4)\n",
    "\n",
    "\n",
    "    df_spots = pd.read_csv(path_csv_folder + path_mask.name[:-4] + \".csv\")\n",
    "    df_spots['in_mask'] = 0\n",
    "    df_spots['mean_intensity'] = 0\n",
    "    df_spots['normalized_mean_intensity'] = 0\n",
    "\n",
    "    list_spots = np.array([[x,y] for x, y in zip(df_spots['x'], df_spots['y'])]) ### add Z coordinate for 3D\n",
    "    snr  = detection.compute_snr_spots(img_fish, list_spots, voxel_size = 108, spot_radius= 300)\n",
    "    dico_snr[path_mask.name[:-4]] = snr\n",
    "    list_mean_intensity = []\n",
    "    mean_norm = np.mean(img_fish_mean[mask == 0])\n",
    "    for i in range(len(df_spots)):\n",
    "        if mask[int(df_spots['x'][i]), int(df_spots['y'][i])]  !=0:\n",
    "            df_spots['in_mask'][i] =  mask[int(df_spots['x'][i]), int(df_spots['y'][i])]\n",
    "            list_mean_intensity.append(img_fish_mean[int(df_spots['x'][i]), int(df_spots['y'][i])])\n",
    "\n",
    "\n",
    "        df_spots['mean_intensity'][i] = img_fish_mean[int(df_spots['x'][i]), int(df_spots['y'][i])]\n",
    "        df_spots['normalized_mean_intensity'][i] = img_fish_mean[int(df_spots['x'][i]), int(df_spots['y'][i])] / mean_norm\n",
    "    df_spots.to_csv(path_csv_folder + path_mask.name[:-9] + \".csv\", index=False)\n",
    "\n",
    "    dico_mean_spots[path_mask.name[:-4]] = np.sum(df_spots['in_mask'] != 0) / len(np.unique(mask)[1:])\n",
    "\n",
    "    dico_mean_intensity[path_mask.name[:-4]] = np.mean(list_mean_intensity)\n",
    "\n",
    "    dico_mean_intensity_normalize[path_mask.name[:-4]] = np.mean(list_mean_intensity) / np.mean(img_fish_mean[mask == 0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "535a7e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean number of spots per images {'Delta_adk1_pCenTy_001.tiff': 5.644970414201183}\n"
     ]
    }
   ],
   "source": [
    "print(f'mean number of spots per images {dico_mean_spots}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ecd4324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean spots intensity per images {'Delta_adk1_pCenTy_001.tiff': 5.644970414201183}\n"
     ]
    }
   ],
   "source": [
    "print(f'mean spots intensity per images {dico_mean_spots}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dff707cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean spots normalized intensity per images {'Delta_adk1_pCenTy_001.tiff': 4.571426791763184}\n"
     ]
    }
   ],
   "source": [
    "print(f'mean spots normalized intensity per images {dico_mean_intensity_normalize}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f2b179",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "batrin",
   "language": "python",
   "name": "batrin"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
